{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'C:\\Users\\KISHORE\\Desktop\\FAANG\\amazon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Open', 'High', 'Low', 'Volume']]\n",
    "y = df['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 3985, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 29.096451\n",
      "Linear Regression: MAE=0.7839976199893378, RMSE=1.025039045479815, R²=0.998773771609204\n",
      "Decision Tree: MAE=2.7297568228485436, RMSE=4.34856684435702, R²=0.9779309900654675\n",
      "Random Forest: MAE=2.495907248979236, RMSE=4.448243029937832, R²=0.9769076801899915\n",
      "XGBoost: MAE=4.353469450708943, RMSE=6.624269610364086, R²=0.9487886116444885\n",
      "LightGBM: MAE=4.9754779591908305, RMSE=7.69524866360583, R²=0.9308907999521294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "#model Instances\n",
    "lr = LinearRegression()\n",
    "dt = DecisionTreeRegressor()\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "xgb = XGBRegressor(n_estimators=100)\n",
    "lgbm = lgb.LGBMRegressor(n_estimators=100)\n",
    "\n",
    "#Training the models\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "dt.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "xgb.fit(X_train, y_train)\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "#predictions\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "y_pred_lgbm = lgbm.predict(X_test)\n",
    "\n",
    "#Evaluations\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse=mean_squared_error(y_test, y_pred)\n",
    "    rmse=np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mae, rmse, r2\n",
    "\n",
    "lr_metrics = evaluate_model(y_test, y_pred_lr)\n",
    "dt_metrics = evaluate_model(y_test, y_pred_dt)\n",
    "rf_metrics = evaluate_model(y_test, y_pred_rf)\n",
    "xgb_metrics = evaluate_model(y_test, y_pred_xgb)\n",
    "lgbm_metrics = evaluate_model(y_test, y_pred_lgbm)\n",
    "\n",
    "#Results\n",
    "print(f\"Linear Regression: MAE={lr_metrics[0]}, RMSE={lr_metrics[1]}, R²={lr_metrics[2]}\")\n",
    "print(f\"Decision Tree: MAE={dt_metrics[0]}, RMSE={dt_metrics[1]}, R²={dt_metrics[2]}\")\n",
    "print(f\"Random Forest: MAE={rf_metrics[0]}, RMSE={rf_metrics[1]}, R²={rf_metrics[2]}\")\n",
    "print(f\"XGBoost: MAE={xgb_metrics[0]}, RMSE={xgb_metrics[1]}, R²={xgb_metrics[2]}\")\n",
    "print(f\"LightGBM: MAE={lgbm_metrics[0]}, RMSE={lgbm_metrics[1]}, R²={lgbm_metrics[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/30 00:56:02 INFO mlflow.tracking.fluent: Experiment with name 'AMAZON - STOCK PREDICTION' does not exist. Creating a new experiment.\n",
      "2025/01/30 00:56:03 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "2025/01/30 00:57:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/01/30 00:58:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/01/30 00:58:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/01/30 00:59:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/01/30 00:59:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "mlflow.set_tracking_uri(\"file:///C:/Users/KISHORE/Desktop/FAANG/mlruns\")\n",
    "\n",
    "mlflow.set_experiment(\"AMAZON - STOCK PREDICTION\")\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_metric(\"lr_mae\", lr_metrics[0])\n",
    "    mlflow.log_metric(\"lr_rmse\", lr_metrics[1])\n",
    "    mlflow.log_metric(\"lr_r2\", lr_metrics[2])\n",
    "\n",
    "    mlflow.log_metric(\"dt_mae\", dt_metrics[0])\n",
    "    mlflow.log_metric(\"dt_rmse\", dt_metrics[1])\n",
    "    mlflow.log_metric(\"dt_r2\", dt_metrics[2])\n",
    "\n",
    "    mlflow.log_metric(\"rf_mae\", rf_metrics[0])\n",
    "    mlflow.log_metric(\"rf_rmse\", rf_metrics[1])\n",
    "    mlflow.log_metric(\"rf_r2\", rf_metrics[2])\n",
    "\n",
    "    mlflow.log_metric(\"xgb_mae\", xgb_metrics[0])\n",
    "    mlflow.log_metric(\"xgb_rmse\", xgb_metrics[1])\n",
    "    mlflow.log_metric(\"xgb_r2\", xgb_metrics[2])\n",
    "\n",
    "    mlflow.log_metric(\"lgbm_mae\", lgbm_metrics[0])\n",
    "    mlflow.log_metric(\"lgbm_rmse\", lgbm_metrics[1])\n",
    "    mlflow.log_metric(\"lgbm_r2\", lgbm_metrics[2])\n",
    "\n",
    "    # Log models\n",
    "    mlflow.sklearn.log_model(lr, \"Linear_Regression_Model\")\n",
    "    mlflow.sklearn.log_model(dt, \"Decision_Tree_Model\")\n",
    "    mlflow.sklearn.log_model(rf, \"Random_Forest_Model\")\n",
    "    mlflow.sklearn.log_model(xgb, \"XGBoost_Model\")\n",
    "    mlflow.sklearn.log_model(lgbm, \"LightGBM_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved as 'amazon_best_model.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "best_model = lr\n",
    "with open(\"amazon_best_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(best_model, file)\n",
    "\n",
    "print(\"Best model saved as 'amazon_best_model.pkl'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
